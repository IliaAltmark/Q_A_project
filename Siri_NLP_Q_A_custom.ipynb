{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Siri_NLP_Q&A_custom.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"53ac42acb5354179945b94d05e69bb81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fc58b77f38884dbc9684d46b15f0be33","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4ffc5ba4b36e4ecd800c35beef1a7b80","IPY_MODEL_3add7204fe824aa8a1aba2cea2e81bca","IPY_MODEL_eee55c1bd3f14a28b53aa0312e1a87a6"]}},"fc58b77f38884dbc9684d46b15f0be33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ffc5ba4b36e4ecd800c35beef1a7b80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef114a180b7345e9862cd20ce76fa77e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63b407e602e04dde972b40a36242d2b4"}},"3add7204fe824aa8a1aba2cea2e81bca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4a5172d6c42540729a0ca77b8f3ab47b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f049d0af03e54ffbaa57f82559d61c58"}},"eee55c1bd3f14a28b53aa0312e1a87a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ec857b3a1a5b4b6b91ebaa34084f3bac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 825kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac35e15fbc74453e9ee06b8a99f4845c"}},"ef114a180b7345e9862cd20ce76fa77e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63b407e602e04dde972b40a36242d2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a5172d6c42540729a0ca77b8f3ab47b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f049d0af03e54ffbaa57f82559d61c58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec857b3a1a5b4b6b91ebaa34084f3bac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ac35e15fbc74453e9ee06b8a99f4845c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"50f35af13d1c471aa8823438c96517b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0c398ad9f8ec4326a9db9e79f2bad418","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_93d9490e79694814a834233c600971b6","IPY_MODEL_8e4478f67a434716a7b49ca087824fc2","IPY_MODEL_829a997c982745baa4137ef1545048d5"]}},"0c398ad9f8ec4326a9db9e79f2bad418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93d9490e79694814a834233c600971b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a63bc81dd7f8413fb66027c74d1085a0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_390f734da3884dfcba81b85de44d919d"}},"8e4478f67a434716a7b49ca087824fc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3cc6c23ca1c64a0cb229a0d4464514a5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec861b2c65d54ea287546de1191c59a9"}},"829a997c982745baa4137ef1545048d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_426ff102cebd49ceb5bbd51a73717418","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 455k/455k [00:00&lt;00:00, 976kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a9ec4024826462992f9196497ff983f"}},"a63bc81dd7f8413fb66027c74d1085a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"390f734da3884dfcba81b85de44d919d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3cc6c23ca1c64a0cb229a0d4464514a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ec861b2c65d54ea287546de1191c59a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"426ff102cebd49ceb5bbd51a73717418":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1a9ec4024826462992f9196497ff983f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31e464e495cb4b56b1dc1c3ecc5c1007":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c6e2f2cf37b84f78baa2724263d90d64","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fd214e187c7a434cbd3690a7063689a4","IPY_MODEL_fe25271d9b3b48b4896120f8791d024c","IPY_MODEL_9ec19b83ef89435c8151e26bdb276287"]}},"c6e2f2cf37b84f78baa2724263d90d64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd214e187c7a434cbd3690a7063689a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1a49beb2ec364385957d645653ba0b14","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_316f9d2cfa01433898c27593cac2f2b3"}},"fe25271d9b3b48b4896120f8791d024c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7d5bdb47ac894e98afdab0a9eb003a40","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f3658dd48f14d6c98e9caa4fb4f9545"}},"9ec19b83ef89435c8151e26bdb276287":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6887784edefc488594f1afb0e4843b01","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 1.18kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a479395f6ae14a1d910a30e8b0bf0518"}},"1a49beb2ec364385957d645653ba0b14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"316f9d2cfa01433898c27593cac2f2b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d5bdb47ac894e98afdab0a9eb003a40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0f3658dd48f14d6c98e9caa4fb4f9545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6887784edefc488594f1afb0e4843b01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a479395f6ae14a1d910a30e8b0bf0518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c61e2159e2c74109b6f2a96b0fda4c47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5f244c4a3b654b60a7bd956b01907a6f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f2de4126418f43ac8733a79efa0b92ea","IPY_MODEL_f231f1195b2445708ae6c873e19136b0","IPY_MODEL_05ae14ef6d304a09840a437baa8d6d5d"]}},"5f244c4a3b654b60a7bd956b01907a6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2de4126418f43ac8733a79efa0b92ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_20a411c41a7842df8341068c2e5035b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53ac24124d15478f81779d0893b4dbe6"}},"f231f1195b2445708ae6c873e19136b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5f970b2b07624ddca0edeec06e5b6d0d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":443,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":443,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce84e23f200d4708a707306127c6b790"}},"05ae14ef6d304a09840a437baa8d6d5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_11b938fc99d146a1ad3920cc9cade8da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 443/443 [00:00&lt;00:00, 20.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69dfa766bfef45b9b56481139f6012d5"}},"20a411c41a7842df8341068c2e5035b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"53ac24124d15478f81779d0893b4dbe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f970b2b07624ddca0edeec06e5b6d0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ce84e23f200d4708a707306127c6b790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11b938fc99d146a1ad3920cc9cade8da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69dfa766bfef45b9b56481139f6012d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"397ae38f64fb43beac684c94548b852d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3c17a551894f492da6b0238e7c5c0c05","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_daf2df604bbd473ab4877dd207f763f2","IPY_MODEL_314fa3183959486cbeafd3e1a6e362df","IPY_MODEL_507d4726a2304f2e95178952c113465d"]}},"3c17a551894f492da6b0238e7c5c0c05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"daf2df604bbd473ab4877dd207f763f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1c34822200454ef7ac69bb8b0d17bc8d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8217affcac754630982532951ec93e70"}},"314fa3183959486cbeafd3e1a6e362df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8ca085bed7d94933932081e74662c95e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1340675298,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1340675298,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea15eceba50c4aeabab306b685f8bdbf"}},"507d4726a2304f2e95178952c113465d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_18515395d1a345b6930bb363a813f6aa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.25G/1.25G [00:22&lt;00:00, 61.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e1dbf21afb14f37b0bdd5801bc8dea5"}},"1c34822200454ef7ac69bb8b0d17bc8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8217affcac754630982532951ec93e70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ca085bed7d94933932081e74662c95e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ea15eceba50c4aeabab306b685f8bdbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"18515395d1a345b6930bb363a813f6aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e1dbf21afb14f37b0bdd5801bc8dea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"V5tbrMPku1Cs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638395464797,"user_tz":-120,"elapsed":22888,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"db0bfd41-9bc4-4a2b-a79d-7cec79834416"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"fleet-rolling"},"source":["## Read"]},{"cell_type":"code","metadata":{"id":"DbD9wV8U90Jr","executionInfo":{"status":"ok","timestamp":1638395465224,"user_tz":-120,"elapsed":439,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["import string\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vyr7X82VcTBH","executionInfo":{"status":"ok","timestamp":1638395465614,"user_tz":-120,"elapsed":36,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Ultramarine_NLP_project/Datasets/podcasts_edits.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"GpUCk6pKc-fI","executionInfo":{"status":"ok","timestamp":1638395465616,"user_tz":-120,"elapsed":36,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"94e6cdb4-4159-48b1-c7d6-f0a0b82a8586"},"source":["df_test.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>questions</th>\n","      <th>answers</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>How much time before there's regular travel ba...</td>\n","      <td>I think it's going to take a while to build a ...</td>\n","      <td>Well I think it's going to take a while to bui...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>There's you ever see the New York Times articl...</td>\n","      <td>I don't know.</td>\n","      <td>I don't know. Yeah, there was a New York Times...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Do you think that they would want us to know o...</td>\n","      <td>I don't know</td>\n","      <td>I don't know of any real civilization. They su...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Even though you're thinking about interplaneta...</td>\n","      <td>No I mean if they show up I'm like, great, OK,...</td>\n","      <td>No I mean if they show up I'm like, great, OK,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           questions  ...                                            context\n","0  How much time before there's regular travel ba...  ...  Well I think it's going to take a while to bui...\n","1  There's you ever see the New York Times articl...  ...  I don't know. Yeah, there was a New York Times...\n","2  Do you think that they would want us to know o...  ...  I don't know of any real civilization. They su...\n","3  Even though you're thinking about interplaneta...  ...  No I mean if they show up I'm like, great, OK,...\n","\n","[4 rows x 3 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"touched-terry","executionInfo":{"status":"ok","timestamp":1638395465617,"user_tz":-120,"elapsed":33,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["answers = df_test.answers\n","contexts = df_test.context\n","questions = df_test.questions"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"handed-zealand"},"source":["## Prepare"]},{"cell_type":"code","metadata":{"id":"precious-windows","executionInfo":{"status":"ok","timestamp":1638395465619,"user_tz":-120,"elapsed":34,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["def add_idx(answers, contexts):\n","    # loop through each answer-context pair\n","    start_positions = []\n","    end_positions = []\n","    for answer, context in zip(answers, contexts):\n","        # gold_text refers to the answer we are expecting to find in context\n","        gold_text = answer\n","        start_idx = context.find(gold_text)\n","        # and ideally this would be the end index...\n","        end_idx = start_idx + len(gold_text)\n","\n","        start_positions.append(start_idx)\n","        end_positions.append(end_idx)\n","    \n","    return start_positions, end_positions"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"-EZVguwtjOwH","executionInfo":{"status":"ok","timestamp":1638395465620,"user_tz":-120,"elapsed":35,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["start_positions, end_positions = add_idx(answers, contexts)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IZgsylgjZJP","executionInfo":{"status":"ok","timestamp":1638395465955,"user_tz":-120,"elapsed":368,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"d71fab7c-1e76-4e50-93bc-0c066dc685bc"},"source":["start_positions, end_positions"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([5, 0, 0, 0], [68, 13, 12, 75])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"cheap-pharmacology"},"source":["## Encode"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8E3V8a6vt6P","executionInfo":{"status":"ok","timestamp":1638395472347,"user_tz":-120,"elapsed":6403,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"fbd93d9f-bb9e-4ae4-8a8c-aaa39149d9da"},"source":["!pip install transformers"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 6.9 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 34.5 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 94.8 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 84.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.0-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 648 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.0 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"]}]},{"cell_type":"code","metadata":{"id":"voluntary-effect","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["53ac42acb5354179945b94d05e69bb81","fc58b77f38884dbc9684d46b15f0be33","4ffc5ba4b36e4ecd800c35beef1a7b80","3add7204fe824aa8a1aba2cea2e81bca","eee55c1bd3f14a28b53aa0312e1a87a6","ef114a180b7345e9862cd20ce76fa77e","63b407e602e04dde972b40a36242d2b4","4a5172d6c42540729a0ca77b8f3ab47b","f049d0af03e54ffbaa57f82559d61c58","ec857b3a1a5b4b6b91ebaa34084f3bac","ac35e15fbc74453e9ee06b8a99f4845c","50f35af13d1c471aa8823438c96517b6","0c398ad9f8ec4326a9db9e79f2bad418","93d9490e79694814a834233c600971b6","8e4478f67a434716a7b49ca087824fc2","829a997c982745baa4137ef1545048d5","a63bc81dd7f8413fb66027c74d1085a0","390f734da3884dfcba81b85de44d919d","3cc6c23ca1c64a0cb229a0d4464514a5","ec861b2c65d54ea287546de1191c59a9","426ff102cebd49ceb5bbd51a73717418","1a9ec4024826462992f9196497ff983f","31e464e495cb4b56b1dc1c3ecc5c1007","c6e2f2cf37b84f78baa2724263d90d64","fd214e187c7a434cbd3690a7063689a4","fe25271d9b3b48b4896120f8791d024c","9ec19b83ef89435c8151e26bdb276287","1a49beb2ec364385957d645653ba0b14","316f9d2cfa01433898c27593cac2f2b3","7d5bdb47ac894e98afdab0a9eb003a40","0f3658dd48f14d6c98e9caa4fb4f9545","6887784edefc488594f1afb0e4843b01","a479395f6ae14a1d910a30e8b0bf0518","c61e2159e2c74109b6f2a96b0fda4c47","5f244c4a3b654b60a7bd956b01907a6f","f2de4126418f43ac8733a79efa0b92ea","f231f1195b2445708ae6c873e19136b0","05ae14ef6d304a09840a437baa8d6d5d","20a411c41a7842df8341068c2e5035b8","53ac24124d15478f81779d0893b4dbe6","5f970b2b07624ddca0edeec06e5b6d0d","ce84e23f200d4708a707306127c6b790","11b938fc99d146a1ad3920cc9cade8da","69dfa766bfef45b9b56481139f6012d5"]},"executionInfo":{"status":"ok","timestamp":1638395483587,"user_tz":-120,"elapsed":11245,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"ff4feefe-80f2-4f7c-c7cf-055c1fa6e009"},"source":["from transformers import BertTokenizerFast\n","tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","\n","test_encodings = tokenizer(contexts.to_list(), questions.to_list(), truncation=True, padding=True)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53ac42acb5354179945b94d05e69bb81","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50f35af13d1c471aa8823438c96517b6","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31e464e495cb4b56b1dc1c3ecc5c1007","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c61e2159e2c74109b6f2a96b0fda4c47","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"behind-technician","executionInfo":{"status":"ok","timestamp":1638395483588,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["def add_token_positions(encodings, answers, start_chars=start_positions, end_chars=end_positions):\n","    # initialize lists to contain the token indices of answer start/end\n","    start_positions = []\n","    end_positions = []\n","    input_offsets = []\n","    for i in range(len(answers)):\n","        # append start/end token position using char_to_token method\n","        start_positions.append(encodings.char_to_token(i, start_chars[i]))\n","        end_positions.append(encodings.char_to_token(i, end_chars[i]))\n","\n","        # if start position is None, the answer passage has been truncated\n","        if start_positions[-1] is None:\n","            start_positions[-1] = tokenizer.model_max_length\n","        # end position cannot be found, char_to_token found space, so shift one token forward\n","        go_back = 1\n","        while end_positions[-1] is None:\n","            end_positions[-1] = encodings.char_to_token(i, end_chars[i]-go_back)\n","            go_back +=1\n","    # update our encodings object with the new token-based start/end positions\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","\n","# apply function to our data\n","add_token_positions(test_encodings, answers.to_list())"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"FId-v9f39VDH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638395483588,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"dbccb278-aa97-4188-ce37-48a5420f8b85"},"source":["test_encodings"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[101, 2092, 1045, 2228, 2009, 1005, 1055, 2183, 2000, 2202, 1037, 2096, 2000, 3857, 1037, 2613, 10585, 2008, 1996, 2613, 1997, 1996, 11207, 2008, 2428, 5609, 2003, 2065, 2057, 1005, 2128, 2893, 2627, 1996, 2307, 11307, 2003, 2079, 2057, 2031, 2438, 4219, 2006, 7733, 2107, 2008, 2065, 1996, 2065, 1996, 25516, 2015, 2013, 3011, 2644, 2746, 1010, 2017, 2071, 5788, 1029, 3398, 1012, 2061, 2008, 2064, 2069, 2022, 2074, 4394, 2028, 2210, 2518, 1012, 2017, 1005, 1040, 2022, 2066, 2017, 1005, 2128, 2006, 1037, 2146, 2712, 8774, 1998, 1996, 2069, 2518, 2017, 1005, 2128, 4394, 2003, 17663, 1039, 1012, 7910, 1010, 2009, 1005, 1055, 2069, 1037, 3043, 1997, 2051, 1010, 2017, 2113, 1012, 3398, 1012, 1998, 2216, 2064, 2022, 14694, 1012, 2061, 2017, 1005, 2310, 2288, 2000, 2031, 2035, 1996, 2477, 4072, 2000, 15770, 10585, 2006, 7733, 1012, 1998, 1996, 3114, 2008, 2216, 3719, 3030, 2746, 2071, 2022, 1012, 2088, 2162, 2093, 1010, 2030, 2009, 2071, 2022, 2349, 2000, 1037, 4030, 6689, 1997, 10585, 1010, 2061, 10585, 2182, 2006, 3011, 2071, 2203, 2007, 1037, 9748, 2030, 1037, 28544, 2030, 3019, 18665, 1012, 3398, 1010, 12175, 14670, 1999, 1996, 2924, 4696, 1012, 3398, 1010, 2009, 2071, 2022, 2066, 1037, 2878, 2186, 1997, 2477, 2066, 1012, 2061, 2066, 2054, 2730, 1996, 18148, 1012, 2092, 1010, 2009, 2347, 1005, 1056, 2074, 2028, 2518, 1010, 2017, 2113, 1010, 2009, 2001, 2066, 1037, 2878, 9129, 1997, 2477, 3047, 1999, 1037, 5216, 1998, 1012, 2017, 2113, 1010, 2096, 2027, 2071, 2031, 2579, 2151, 2028, 1997, 2216, 2477, 1010, 2027, 2018, 2066, 2093, 2477, 4148, 1998, 2053, 18148, 1010, 2029, 2003, 2785, 1997, 6429, 2008, 21843, 2015, 2024, 2145, 2182, 1012, 3398, 1010, 2216, 6616, 2545, 1010, 2092, 1010, 2027, 1005, 2128, 24501, 18622, 4765, 21843, 2015, 2008, 2027, 2035, 2008, 2444, 2006, 13121, 2098, 6240, 1998, 2027, 2293, 22005, 6240, 1012, 1998, 2061, 1999, 1037, 2151, 2785, 1997, 16775, 3663, 1010, 2045, 1005, 1055, 1037, 2843, 1997, 2757, 7329, 1998, 1996, 21843, 2015, 2293, 2009, 1012, 2061, 2008, 1005, 1055, 2339, 2027, 1005, 2128, 2105, 21843, 2015, 1998, 12883, 1998, 23827, 1998, 14021, 15603, 2015, 23019, 1010, 2029, 2003, 2339, 2057, 1005, 2128, 2182, 1012, 3398, 1010, 3599, 1012, 2256, 2307, 1010, 2307, 1010, 2307, 1010, 2307, 1010, 2307, 1010, 2307, 14472, 2020, 1012, 2054, 1037, 4326, 2518, 2619, 2066, 2017, 2018, 2000, 2272, 2013, 1012, 2061, 2045, 1005, 1055, 3246, 1012, 2045, 1005, 1055, 3246, 2005, 2035, 2017, 28156, 2041, 2045, 1012, 3398, 1010, 2092, 1010, 2017, 2064, 2175, 2000, 7733, 1012, 2074, 2562, 2725, 2115, 19453, 1012, 102, 2129, 2172, 2051, 2077, 2045, 1005, 1055, 3180, 3604, 2067, 1998, 5743, 2000, 7733, 1029, 102], [101, 1045, 2123, 1005, 1056, 2113, 1012, 3398, 1010, 2045, 2001, 1037, 2047, 2259, 2335, 3720, 1999, 3174, 9171, 2008, 2001, 17555, 2023, 1010, 1998, 2045, 1005, 1055, 1037, 3232, 1997, 2045, 1005, 1055, 1037, 3232, 2060, 2367, 29426, 2015, 2008, 2020, 2200, 2714, 1012, 2027, 2020, 2667, 2000, 3275, 2041, 2054, 2122, 2477, 2020, 1998, 2339, 1012, 1998, 2009, 2001, 2036, 1999, 1996, 2522, 17258, 4335, 7427, 2008, 1996, 9915, 2001, 4011, 2000, 2713, 1012, 3398, 1010, 8801, 2024, 2667, 2000, 3275, 2041, 2054, 2035, 2023, 4485, 2003, 1012, 2061, 2027, 3046, 2000, 2131, 2068, 2000, 2713, 2035, 1996, 2592, 2027, 2031, 2306, 8380, 2420, 1012, 9826, 1010, 1045, 2228, 1045, 2052, 2113, 2065, 2045, 2020, 12114, 1012, 1045, 2052, 3246, 2061, 1012, 2008, 1005, 1055, 2339, 1045, 1005, 1049, 4851, 1012, 2017, 2113, 1010, 1045, 1045, 1005, 1040, 2022, 8660, 2006, 2008, 2066, 2066, 2017, 2323, 3422, 2008, 4512, 2007, 17244, 1012, 2009, 1005, 1055, 2066, 2182, 1005, 1055, 1996, 2518, 1012, 102, 2045, 1005, 1055, 2017, 2412, 2156, 1996, 2047, 2259, 2335, 3720, 2008, 2234, 2041, 1999, 3174, 9171, 2055, 1996, 4933, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2123, 1005, 1056, 2113, 1997, 2151, 2613, 10585, 1012, 2027, 2469, 1012, 2256, 11259, 1045, 2812, 1010, 2065, 2027, 2359, 2149, 2000, 2113, 1010, 5525, 2027, 2071, 2074, 2265, 2039, 1998, 3328, 2091, 2364, 2395, 1010, 2017, 2113, 1010, 4931, 1010, 1045, 1005, 1049, 2019, 7344, 1012, 4638, 2033, 2041, 1010, 2017, 2113, 1010, 2157, 1012, 2182, 1005, 1055, 2026, 25516, 1012, 1045, 2074, 2455, 1999, 1996, 2690, 1997, 2335, 2675, 1012, 1045, 1005, 1040, 2022, 2066, 1010, 2157, 1010, 7929, 1012, 2030, 25215, 2099, 2058, 5116, 1048, 1012, 1037, 1012, 1012, 3398, 1010, 3398, 1012, 2057, 2020, 2066, 1010, 7929, 1010, 2057, 2903, 2017, 1012, 3398, 1012, 2061, 3649, 2024, 2027, 2024, 2200, 11259, 1010, 2200, 11259, 2138, 12114, 1012, 102, 2079, 2017, 2228, 2008, 2027, 2052, 2215, 2149, 2000, 2113, 2030, 2079, 2017, 2228, 2027, 2052, 2074, 2022, 14158, 1998, 2437, 2469, 2057, 2123, 1005, 1056, 6271, 9731, 2039, 1010, 2052, 2057, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2053, 1045, 2812, 2065, 2027, 2265, 2039, 1045, 1005, 1049, 2066, 1010, 2307, 1010, 7929, 1010, 2085, 2023, 2003, 2047, 2592, 1012, 2021, 2017, 2113, 2054, 2019, 5875, 2126, 1997, 5128, 2023, 2003, 2047, 2592, 1010, 2023, 2047, 2592, 2066, 2073, 2024, 2017, 4364, 2039, 6229, 2085, 1029, 3398, 1012, 2061, 4312, 1010, 4952, 1010, 2065, 1045, 2156, 2070, 3350, 2005, 12114, 1010, 1045, 1005, 2222, 2022, 2066, 1045, 1005, 2222, 2022, 1996, 2034, 2000, 2022, 2066, 12114, 1010, 2017, 2113, 1029, 2157, 1012, 2059, 2017, 1005, 2222, 8556, 1012, 2021, 2127, 2059, 1010, 2017, 2228, 2009, 1005, 1055, 2785, 1997, 1037, 5949, 1997, 2051, 1012, 3398, 1010, 3398, 1012, 2009, 5791, 3849, 2066, 1037, 5949, 1997, 2051, 2065, 2498, 1005, 1055, 3047, 2061, 2521, 1012, 2017, 2228, 2055, 2035, 1996, 2111, 2008, 1045, 1005, 2310, 2042, 20059, 12114, 2005, 2037, 2878, 2166, 1998, 2027, 2031, 2200, 2210, 2000, 2265, 2005, 2009, 1012, 2092, 1010, 2017, 2113, 1010, 2045, 1005, 1055, 2060, 2084, 4658, 3441, 1012, 3398, 1012, 1045, 2812, 1010, 2057, 2031, 18821, 2183, 2035, 2058, 1996, 2088, 2559, 2012, 2477, 1012, 2017, 2113, 1010, 2045, 1005, 1055, 2023, 2111, 2066, 2065, 2057, 2020, 2000, 2424, 2242, 2066, 2292, 1005, 1055, 2360, 2066, 1037, 14291, 1997, 23431, 1010, 2074, 2066, 1037, 2028, 4960, 7394, 23431, 1010, 2009, 1005, 1055, 1999, 1996, 2690, 1997, 1996, 11918, 1012, 1045, 2514, 2066, 12114, 2005, 2469, 1012, 2045, 1005, 1055, 2053, 2126, 2027, 2071, 2031, 2081, 23431, 2067, 1012, 2045, 2003, 2053, 2126, 1012, 2008, 1005, 1055, 2524, 1012, 2008, 1005, 1055, 2035, 2028, 2079, 2123, 1005, 1056, 2130, 2342, 1037, 3274, 2066, 1037, 3274, 2052, 2022, 2066, 1010, 4931, 1010, 2096, 7588, 1010, 2027, 2134, 1005, 1056, 2031, 7588, 2067, 2059, 1012, 2061, 2009, 2442, 2022, 12114, 1012, 2021, 2021, 2130, 2074, 2066, 2070, 3935, 3384, 7630, 22637, 1010, 2505, 2066, 2505, 2066, 2008, 1012, 2157, 1012, 2498, 2066, 2008, 2008, 2057, 2071, 2391, 2000, 2008, 2057, 2064, 1005, 1056, 2079, 2673, 2008, 2057, 2179, 7611, 2135, 2003, 8335, 2007, 1996, 2051, 1010, 1996, 2974, 2027, 2018, 2012, 2008, 2051, 1012, 23005, 2135, 1012, 102, 2130, 2295, 2017, 1005, 2128, 3241, 2055, 6970, 11751, 18219, 3604, 1010, 2017, 2123, 1005, 1056, 2428, 2228, 2055, 12114, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'start_positions': [2, 1, 1, 1], 'end_positions': [16, 6, 5, 22]}"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"specified-daughter"},"source":["---\n","\n","# PyTorch implementation"]},{"cell_type":"code","metadata":{"id":"recognized-proceeding","executionInfo":{"status":"ok","timestamp":1638395483589,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["import torch\n","\n","class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","test_dataset = SquadDataset(test_encodings)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"alive-qatar","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["397ae38f64fb43beac684c94548b852d","3c17a551894f492da6b0238e7c5c0c05","daf2df604bbd473ab4877dd207f763f2","314fa3183959486cbeafd3e1a6e362df","507d4726a2304f2e95178952c113465d","1c34822200454ef7ac69bb8b0d17bc8d","8217affcac754630982532951ec93e70","8ca085bed7d94933932081e74662c95e","ea15eceba50c4aeabab306b685f8bdbf","18515395d1a345b6930bb363a813f6aa","2e1dbf21afb14f37b0bdd5801bc8dea5"]},"executionInfo":{"status":"ok","timestamp":1638395509720,"user_tz":-120,"elapsed":26136,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"a0157828-538e-4e0c-bd88-acda385b3a48"},"source":["from transformers import BertForQuestionAnswering\n","model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"397ae38f64fb43beac684c94548b852d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"spectacular-course","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638395521704,"user_tz":-120,"elapsed":12022,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"da33ad38-521d-4a72-a818-b338a76fd060"},"source":["from torch.utils.data import DataLoader\n","from transformers import AdamW\n","from tqdm import tqdm\n","\n","# setup GPU/CPU\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","# move model over to detected device\n","model.to(device)\n","# # activate training mode of model\n","# model.train()\n","# # initialize adam optimizer with weight decay (reduces chance of overfitting)\n","# optim = AdamW(model.parameters(), lr=5e-5)\n","\n","# # initialize data loader for training data\n","# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","# for epoch in range(3):\n","#     # set model to train mode\n","#     model.train()\n","#     # setup loop (we use tqdm for the progress bar)\n","#     loop = tqdm(train_loader, leave=True)\n","#     for batch in loop:\n","#         # initialize calculated gradients (from prev step)\n","#         optim.zero_grad()\n","#         # pull all the tensor batches required for training\n","#         input_ids = batch['input_ids'].to(device)\n","#         attention_mask = batch['attention_mask'].to(device)\n","#         start_positions = batch['start_positions'].to(device)\n","#         end_positions = batch['end_positions'].to(device)\n","#         # train model on batch and return outputs (incl. loss)\n","#         outputs = model(input_ids, attention_mask=attention_mask,\n","#                         start_positions=start_positions,\n","#                         end_positions=end_positions)\n","#         # extract loss\n","#         loss = outputs[0]\n","#         # calculate loss for every parameter that needs grad update\n","#         loss.backward()\n","#         # update parameters\n","#         optim.step()\n","#         # print relevant info to progress bar\n","#         loop.set_description(f'Epoch {epoch}')\n","#         loop.set_postfix(loss=loss.item())"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"otherwise-religion","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638395522312,"user_tz":-120,"elapsed":641,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"3fdba679-d7b3-4d96-f76f-09d70b55e086"},"source":["# switch model out of training mode\n","model.eval()\n","\n","#val_sampler = SequentialSampler(val_dataset)\n","test_loader = DataLoader(test_dataset, batch_size=16)\n","\n","acc = []\n","\n","# initialize loop for progress bar\n","loop = tqdm(test_loader)\n","# loop through batches\n","for batch in loop:\n","    # we don't need to calculate gradients as we're not training\n","    with torch.no_grad():\n","        # pull batched items from loader\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        start_true = batch['start_positions'].to(device)\n","        end_true = batch['end_positions'].to(device)\n","        # make predictions\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # pull preds out\n","        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n","        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n","        # calculate accuracy for both and append to accuracy list\n","        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n","        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n","# calculate average accuracy in total\n","acc = sum(acc)/len(acc)\n","acc"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00,  3.24it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"pressed-request","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638395522314,"user_tz":-120,"elapsed":30,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"13af8120-7c00-4bb8-a7d2-38aac9e7e021"},"source":["print(\"T/F\\tstart\\tend\\n\")\n","for i in range(len(start_true)):\n","    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n","          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["T/F\tstart\tend\n","\n","true\t2\t16\n","pred\t0\t0\n","\n","true\t1\t6\n","pred\t109\t117\n","\n","true\t1\t5\n","pred\t115\t116\n","\n","true\t1\t22\n","pred\t0\t0\n","\n"]}]},{"cell_type":"code","metadata":{"id":"za7Llu1lJ7Xj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638395522318,"user_tz":-120,"elapsed":28,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"fbef5426-265c-4c9c-c69a-01677de4ea40"},"source":["for i in range(len(start_true)):\n","  all_tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n","  print('<------->')\n","  print(f'Q: {questions[i]}')\n","  print(f'Pred A: {\" \".join(all_tokens[start_pred[i]:end_pred[i]+1])}')"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["<------->\n","Q: How much time before there's regular travel back and forth to Mars?\n","Pred A: [CLS]\n","<------->\n","Q: There's you ever see the New York Times article that came out in twenty seventeen about the stuff?\n","Pred A: i think i would know if there were aliens\n","<------->\n","Q: Do you think that they would want us to know or do you think they would just be observing and making sure we don't blow ourselves up, would we?\n","Pred A: very subtle\n","<------->\n","Q: Even though you're thinking about interplanetary travel, you don't really think about aliens?\n","Pred A: [CLS]\n"]}]},{"cell_type":"markdown","metadata":{"id":"LZto_XRruzXq"},"source":["# Implementing weights based on location"]},{"cell_type":"code","metadata":{"id":"_JklYj6BOJ0h","executionInfo":{"status":"ok","timestamp":1638395522318,"user_tz":-120,"elapsed":22,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["answers = outputs['start_logits'].shape[0]\n","indexes = outputs['start_logits'].shape[1]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"QX_J23xfdhfm","executionInfo":{"status":"ok","timestamp":1638395522319,"user_tz":-120,"elapsed":21,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["softmax = torch.nn.Softmax(dim=1)\n","start_soft = softmax(outputs['start_logits'])\n","end_soft = softmax(outputs['end_logits'])"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"FjQSuYvEUnyw","executionInfo":{"status":"ok","timestamp":1638395522320,"user_tz":-120,"elapsed":21,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["weighted_indexes = np.zeros([answers, indexes, indexes])"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-mDl2vgObqoe","executionInfo":{"status":"ok","timestamp":1638395522320,"user_tz":-120,"elapsed":20,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["lowest_weight = 0.5\n","weights = np.linspace(1, lowest_weight, num=indexes)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYOPjDa9aClV","executionInfo":{"status":"ok","timestamp":1638395531269,"user_tz":-120,"elapsed":8967,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["for i, positions in enumerate(zip(start_soft, end_soft)):\n","  start_pos = positions[0]\n","  end_pos = positions[1]\n","  for start_index, start_token in enumerate(start_pos):\n","    for end_index, end_token in enumerate(end_pos):\n","      if start_index <= end_index:\n","        weighted_indexes[i,start_index,end_index] = ((start_token.item() + end_token.item())/2) * weights[start_index]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHaA1MYccZN0","executionInfo":{"status":"ok","timestamp":1638395531270,"user_tz":-120,"elapsed":40,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":["start_pred = []\n","end_pred = []\n","for i in range(weighted_indexes.shape[0]):\n","  max_start = weighted_indexes[i].max(axis=1).argmax()\n","  max_end = weighted_indexes[i].argmax(axis=1)[max_start]\n","  start_pred.append(max_start)\n","  end_pred.append(max_end)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sVV5TaFq9mD","executionInfo":{"status":"ok","timestamp":1638395531271,"user_tz":-120,"elapsed":38,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"f3cb1742-e645-4512-d412-2e0b5cd26b36"},"source":["print(\"T/F\\tstart\\tend\\n\")\n","for i in range(len(start_true)):\n","    print(f\"true\\t{start_true[i]}\\t{end_true[i]}\\n\"\n","          f\"pred\\t{start_pred[i]}\\t{end_pred[i]}\\n\")"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["T/F\tstart\tend\n","\n","true\t2\t16\n","pred\t0\t0\n","\n","true\t1\t6\n","pred\t109\t117\n","\n","true\t1\t5\n","pred\t115\t116\n","\n","true\t1\t22\n","pred\t0\t0\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QJpaUeAq9mb","executionInfo":{"status":"ok","timestamp":1638395531273,"user_tz":-120,"elapsed":31,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}},"outputId":"1d9c7b84-f07c-4ee1-edb4-61adfaef68d6"},"source":["for i in range(len(start_true)):\n","  all_tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n","  print('<------->')\n","  print(f'Q: {questions[i]}')\n","  print(f'Pred A: {\" \".join(all_tokens[start_pred[i]:end_pred[i]+1])}')"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["<------->\n","Q: How much time before there's regular travel back and forth to Mars?\n","Pred A: [CLS]\n","<------->\n","Q: There's you ever see the New York Times article that came out in twenty seventeen about the stuff?\n","Pred A: i think i would know if there were aliens\n","<------->\n","Q: Do you think that they would want us to know or do you think they would just be observing and making sure we don't blow ourselves up, would we?\n","Pred A: very subtle\n","<------->\n","Q: Even though you're thinking about interplanetary travel, you don't really think about aliens?\n","Pred A: [CLS]\n"]}]},{"cell_type":"code","metadata":{"id":"KtSDRkvQreqP","executionInfo":{"status":"ok","timestamp":1638395531274,"user_tz":-120,"elapsed":27,"user":{"displayName":"Ilia Altmark","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEfV6aI8hyGAqc6XWISDmbqFfGwPQWqphIy4Bwqg=s64","userId":"01715062369510615404"}}},"source":[""],"execution_count":26,"outputs":[]}]}